name: Database Operations

on:
  push:
    branches: [development, staging, main]
  pull_request:
    branches: [development, staging, main]
  workflow_dispatch:  # Allow manual triggering

jobs:
  database-operations:
    runs-on: ubuntu-latest
    
    # Define environment based on branch
    environment: ${{ github.ref == 'refs/heads/main' && 'production' || github.ref == 'refs/heads/staging' && 'staging' || 'development' }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Configure environment variables
        id: config
        run: |
          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            echo "env_name=production" >> $GITHUB_OUTPUT
            echo "db_file=dpat_production.db" >> $GITHUB_OUTPUT
            echo "log_level=warning" >> $GITHUB_OUTPUT
          elif [[ "${{ github.ref }}" == "refs/heads/staging" ]]; then
            echo "env_name=staging" >> $GITHUB_OUTPUT
            echo "db_file=dpat_staging.db" >> $GITHUB_OUTPUT
            echo "log_level=information" >> $GITHUB_OUTPUT
          else
            echo "env_name=development" >> $GITHUB_OUTPUT
            echo "db_file=dpat_development.db" >> $GITHUB_OUTPUT
            echo "log_level=debug" >> $GITHUB_OUTPUT
          fi
      
      - name: Display environment information
        run: |
          echo "ðŸŒ Environment: ${{ steps.config.outputs.env_name }}"
          echo "ðŸ’¾ Database file: ${{ steps.config.outputs.db_file }}"
          echo "ðŸ“‹ Log level: ${{ steps.config.outputs.log_level }}"
          echo "ðŸ” Repository structure:"
          ls -la
          ls -la DataPrivacyAuditTool/ || echo "DataPrivacyAuditTool directory not found at root"
      
      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: '9.0'
      
      - name: Install SQLite tools
        run: sudo apt-get update && sudo apt-get install -y sqlite3
      
      - name: Validate database
        id: validate-db
        continue-on-error: true
        run: |
          DB_PATH="DataPrivacyAuditTool/${{ steps.config.outputs.db_file }}"
          
          if [ -f "$DB_PATH" ]; then
            echo "Database found at: $DB_PATH"
            echo "Database size: $(stat -c%s "$DB_PATH") bytes"
            
            # Simple validation - check if it's a valid SQLite database
            if sqlite3 "$DB_PATH" "PRAGMA integrity_check;" | grep -q "ok"; then
              echo "âœ… Database integrity check passed"
              echo "db_valid=true" >> $GITHUB_OUTPUT
              
              # List tables
              echo "ðŸ“Š Database tables:"
              sqlite3 "$DB_PATH" ".tables"
              
              # Count records in AuditHistories
              RECORD_COUNT=$(sqlite3 "$DB_PATH" "SELECT COUNT(*) FROM AuditHistories;" 2>/dev/null || echo "Table not found")
              echo "ðŸ“ AuditHistories record count: $RECORD_COUNT"
            else
              echo "âŒ Database integrity check failed"
              echo "db_valid=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "âš ï¸ Database file not found at expected path: $DB_PATH"
            echo "Looking for similar database files:"
            find . -name "*.db" -type f | grep -i dpat || echo "No database files found"
            echo "db_valid=false" >> $GITHUB_OUTPUT
          fi
      
      - name: Perform environment-specific database operations
        run: |
          DB_PATH="DataPrivacyAuditTool/${{ steps.config.outputs.db_file }}"
          
          echo "ðŸ”§ Performing ${{ steps.config.outputs.env_name }}-specific operations"
          
          if [ -f "$DB_PATH" ] && [ "${{ steps.validate-db.outputs.db_valid }}" == "true" ]; then
            # Create backup directory with environment-specific subdirectory
            mkdir -p "./backups/${{ steps.config.outputs.env_name }}"
            
            # Create timestamped backup
            TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
            BACKUP_PATH="./backups/${{ steps.config.outputs.env_name }}/${{ steps.config.outputs.db_file }}_${TIMESTAMP}.bak"
            cp "$DB_PATH" "$BACKUP_PATH"
            echo "ðŸ’¾ Database backup created at: $BACKUP_PATH"
            
            # Different operations per environment
            if [[ "${{ steps.config.outputs.env_name }}" == "production" ]]; then
              # Production: Add database statistics to a statistics table
              echo "ðŸ“Š Creating database usage statistics for production"
              sqlite3 "$DB_PATH" "CREATE TABLE IF NOT EXISTS DbStatistics (id INTEGER PRIMARY KEY, 
                                                                          check_date TEXT, 
                                                                          total_audits INTEGER, 
                                                                          avg_score REAL);"
                                                                          
              # Insert statistics record with current date and aggregate data
              sqlite3 "$DB_PATH" "INSERT INTO DbStatistics (check_date, total_audits, avg_score) 
                                SELECT datetime('now'), 
                                       COUNT(*), 
                                       AVG(OverallScore) 
                                FROM AuditHistories;"
                                
            elif [[ "${{ steps.config.outputs.env_name }}" == "staging" ]]; then
              # Staging: Archive old records to maintain performance
              echo "ðŸ§¹ Archiving old records in staging environment"
              # Create archive table if it doesn't exist
              sqlite3 "$DB_PATH" "CREATE TABLE IF NOT EXISTS ArchivedAuditHistories AS SELECT * FROM AuditHistories WHERE 1=0;"
              
              # Move records older than 30 days to archive
              sqlite3 "$DB_PATH" "INSERT INTO ArchivedAuditHistories 
                                SELECT * FROM AuditHistories 
                                WHERE julianday('now') - julianday(AuditDate) > 30;"
                                
              sqlite3 "$DB_PATH" "DELETE FROM AuditHistories 
                                WHERE julianday('now') - julianday(AuditDate) > 30;"
                                
            else
              # Development: Add test data for development purposes
              echo "ðŸ§ª Adding sample test data in development environment"
              sqlite3 "$DB_PATH" "INSERT INTO AuditHistories (Username, OverallScore, AuditDate, CreatedAt) 
                                VALUES ('test_user', 92.5, datetime('now'), datetime('now'));"
            fi
            
            # Verify the changes
            echo "âœ… Database operations completed successfully"
            echo "ðŸ“Š Updated table structure:"
            sqlite3 "$DB_PATH" ".tables"
          else
            echo "âš ï¸ Skipping database operations as database is invalid or not found"
          fi
      
      - name: Generate database report
        run: |
          # Create the reports directory
          mkdir -p ./reports
          
          # Generate a timestamped report file
          TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
          REPORT_FILE="./reports/${{ steps.config.outputs.env_name }}_db_report_${TIMESTAMP}.md"
          
          echo "ðŸ“ Generating database report for ${{ steps.config.outputs.env_name }} environment"
          
          # Start building the report content
          cat > "$REPORT_FILE" << EOF
          # Database Operations Report: ${{ steps.config.outputs.env_name }}
          
          **Date:** $(date -u "+%Y-%m-%d %H:%M:%S UTC")
          **Branch:** ${{ github.ref_name }}
          **Triggered by:** ${{ github.event_name }}
          
          ## Environment Configuration
          - **Environment:** ${{ steps.config.outputs.env_name }}
          - **Database File:** ${{ steps.config.outputs.db_file }}
          - **Log Level:** ${{ steps.config.outputs.log_level }}
          
          EOF
          
          # Add database status to the report
          if [ -f "DataPrivacyAuditTool/${{ steps.config.outputs.db_file }}" ]; then
            DB_SIZE=$(stat -c%s "DataPrivacyAuditTool/${{ steps.config.outputs.db_file }}")
            
            cat >> "$REPORT_FILE" << EOF
          ## Database Status
          - **File Found:** âœ… Yes
          - **Size:** ${DB_SIZE} bytes
          - **Integrity Check:** ${{ steps.validate-db.outputs.db_valid == 'true' && 'âœ… Passed' || 'âŒ Failed' }}
          
          EOF
            
            # If database is valid, add more detailed information
            if [ "${{ steps.validate-db.outputs.db_valid }}" == "true" ]; then
              # Get table list
              TABLES=$(sqlite3 "DataPrivacyAuditTool/${{ steps.config.outputs.db_file }}" ".tables")
              
              # Get record counts for key tables
              AUDIT_COUNT=$(sqlite3 "DataPrivacyAuditTool/${{ steps.config.outputs.db_file }}" "SELECT COUNT(*) FROM AuditHistories;" 2>/dev/null || echo "Table not found")
              
              cat >> "$REPORT_FILE" << EOF
          ## Database Details
          - **Tables:** ${TABLES}
          - **AuditHistories Count:** ${AUDIT_COUNT}
          
          ## Operations Performed
          EOF
              
              # Add environment-specific operation details
              if [[ "${{ steps.config.outputs.env_name }}" == "production" ]]; then
                cat >> "$REPORT_FILE" << EOF
          - âœ… Created backup
          - âœ… Generated database statistics
          - âœ… Recorded usage metrics
          
          ## Recommendations
          - Consider implementing a scheduled backup policy
          - Monitor database size growth over time
          - Implement database performance monitoring
          EOF
              elif [[ "${{ steps.config.outputs.env_name }}" == "staging" ]]; then
                cat >> "$REPORT_FILE" << EOF
          - âœ… Created backup
          - âœ… Archived old records
          - âœ… Optimized database for testing
          
          ## Recommendations
          - Regular testing of data migration scripts
          - Validate staging data against production schemas
          - Implement database performance testing
          EOF
              else
                cat >> "$REPORT_FILE" << EOF
          - âœ… Created backup
          - âœ… Added test data
          - âœ… Prepared for development use
          
          ## Recommendations
          - Use realistic test data for development
          - Implement database schema version control
          - Add database migration tests
          EOF
              fi
            else
              cat >> "$REPORT_FILE" << EOF
          ## Operations Performed
          - âŒ Database operations skipped due to validation failure
          
          ## Recommendations
          - Investigate database integrity issues
          - Restore from most recent backup
          - Verify schema matches expected structure
          EOF
            fi
          else
            cat >> "$REPORT_FILE" << EOF
          ## Database Status
          - **File Found:** âŒ No
          
          ## Operations Performed
          - âŒ Database operations skipped as file was not found
          
          ## Recommendations
          - Create initial database schema
          - Verify database file is not excluded from version control
          - Check deployment process for database initialization
          EOF
          fi
          
          # Final footer
          cat >> "$REPORT_FILE" << EOF
          
          ---
          *This report was automatically generated by the Database Operations workflow.*
          EOF
          
          echo "âœ… Report generated at: $REPORT_FILE"
      
      - name: Upload database backup
        if: steps.validate-db.outputs.db_valid == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: ${{ steps.config.outputs.env_name }}-database-backup
          path: ./backups/${{ steps.config.outputs.env_name }}/*.bak
          retention-days: 7
      
      - name: Upload database report
        uses: actions/upload-artifact@v4
        with:
          name: ${{ steps.config.outputs.env_name }}-database-report
          path: ./reports/${{ steps.config.outputs.env_name }}_db_report_*.md
          retention-days: 7
